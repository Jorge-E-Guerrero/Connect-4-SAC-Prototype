{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from collections import namedtuple, deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "from pettingzoo.classic import connect_four_v3\n",
    "\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if GPU is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = connect_four_v3.env(render_mode=\"human\")\n",
    "env = connect_four_v3.env()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 0.0005\n",
    "TAU = 0.001\n",
    "LR = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of actions from gym action space\n",
    "n_actions = 7\n",
    "\n",
    "# Get the number of state observations\n",
    "observation, reward, termination, truncation, info = env.last()\n",
    "\n",
    "#observation_shape = np.array(observation[\"observation\"]).reshape(1,-1)\n",
    "n_observations = 84\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(state_size, 128)\n",
    "        self.linear2 = nn.Linear(128, 128)\n",
    "        self.linear3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        return self.linear3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAC:\n",
    "    def __init__(self,lr,batch_size,gamma,tau, eps_start,eps_end,eps_dec, n_observations,n_actions):\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.epsilon = eps_start\n",
    "        self.eps_end = eps_end\n",
    "        self.eps_dec = eps_dec\n",
    "        \n",
    "        self.n_observations = n_observations\n",
    "        self.n_actions = n_actions\n",
    "\n",
    "        self.policy_net = ActorNetwork(n_observations, n_actions).to(device)\n",
    "        self.policy_optimizer = optim.Adam(self.policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "\n",
    "        self.critic_net_1 = CriticNetwork(n_observations, n_actions).to(device)\n",
    "        self.critic_optimizer_1 = optim.Adam(self.critic_net_1.parameters(), lr=LR, amsgrad=True)\n",
    "        self.critic_net_2 = CriticNetwork(n_observations, n_actions).to(device)\n",
    "        self.critic_optimizer_2 = optim.Adam(self.critic_net_2.parameters(), lr=LR, amsgrad=True)\n",
    "\n",
    "        self.target_net_1 = CriticNetwork(n_observations, n_actions).to(device)\n",
    "        self.target_optimizer_1 = optim.Adam(self.target_net_1.parameters(), lr=LR, amsgrad=True)\n",
    "        self.target_net_2 = CriticNetwork(n_observations, n_actions).to(device)\n",
    "        self.target_optimizer_2 = optim.Adam(self.target_net_2.parameters(), lr=LR, amsgrad=True)\n",
    "\n",
    "\n",
    "        self.memory = []\n",
    "\n",
    "        self.criterion_1 = nn.MSELoss()\n",
    "        self.criterion_2 = nn.MSELoss()\n",
    "        self.probs = []\n",
    "        self.loss = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def choose_action(self, agent, state):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = env.action_space(agent).sample(state[\"action_mask\"])\n",
    "        else:\n",
    "            action_mask = torch.tensor(state[\"action_mask\"])\n",
    "            state_tensor = torch.FloatTensor(np.array(state[\"observation\"]).reshape(1,-1))\n",
    "            \n",
    "            q_values = self.policy_net(state_tensor)\n",
    "            max, min= torch.max(q_values), torch.min(q_values)\n",
    "            q_values = (q_values-min)/ (max-min)\n",
    "            valid_actions = action_mask *  q_values\n",
    "\n",
    "            #print(valid_actions)\n",
    "\n",
    "            #self.probs = valid_actions\n",
    "\n",
    "            action = np.argmax(valid_actions.detach().numpy())\n",
    "\n",
    "\n",
    "            #self.policy_net.train()\n",
    "            self.decrement_epsilon()\n",
    "\n",
    "        return action\n",
    "    \n",
    "    def update(self, state, new_state, reward,done):\n",
    "        \n",
    "        \n",
    "        \n",
    "        state_tensor = torch.FloatTensor(np.array(state[\"observation\"]).reshape(1,-1))\n",
    "        new_state_tensor = torch.FloatTensor(np.array(new_state[\"observation\"]).reshape(1,-1))\n",
    "\n",
    "        next_action_prob = self.policy_net(state_tensor)\n",
    "\n",
    "\n",
    "        next_q_target_1 = self.target_net_1(new_state_tensor)\n",
    "        next_q_target_2 = self.target_net_2(new_state_tensor)\n",
    "\n",
    "        min_next_q_target = torch.min(next_q_target_1, next_q_target_2)\n",
    "        next_q = (100 * reward) + (1 - done) * self.gamma * (min_next_q_target - next_action_prob)\n",
    "\n",
    "        Value_1 = self.critic_net_1(state_tensor)\n",
    "        value_2 = self.critic_net_2(state_tensor)\n",
    "\n",
    "        loss_1 = self.criterion_1(Value_1,next_q)\n",
    "        loss_2 = self.criterion_2(value_2,next_q)\n",
    "\n",
    "        self.loss = (loss_1 + loss_2)/2\n",
    "\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        self.critic_optimizer_1.zero_grad()\n",
    "        self.critic_optimizer_2.zero_grad()\n",
    "        self.target_optimizer_1.zero_grad()\n",
    "        self.target_optimizer_2.zero_grad()\n",
    "\n",
    "        self.loss.backward()\n",
    "        \n",
    "        self.policy_optimizer.step()\n",
    "        self.critic_optimizer_1.step()\n",
    "        self.critic_optimizer_2.step()\n",
    "        self.target_optimizer_1.step()\n",
    "        self.target_optimizer_2.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def update_memory(self,state, reward, termination, truncation, info):\n",
    "        self.memory.append((state, reward, termination, truncation, info))\n",
    "\n",
    "    def clear_memory(self):\n",
    "        self.memory = []\n",
    "\n",
    "\n",
    "    def optimize(self):\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        self.critic_optimizer_1.zero_grad()\n",
    "        self.critic_optimizer_2.zero_grad()\n",
    "        self.target_optimizer_1.zero_grad()\n",
    "        self.target_optimizer_2.zero_grad()\n",
    "        \n",
    "        self.policy_optimizer.step()\n",
    "        self.critic_optimizer_1.step()\n",
    "        self.critic_optimizer_2.step()\n",
    "        self.target_optimizer_1.step()\n",
    "        self.target_optimizer_2.step()\n",
    "    \n",
    "    def decrement_epsilon(self):\n",
    "        self.epsilon = self.epsilon - self.eps_dec \\\n",
    "            if self.epsilon > self.eps_end else self.eps_end\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef update(batch_size,gamma=0.99,soft_tau=1e-2,):\\n    \\n    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\\n\\n    state      = torch.FloatTensor(state).to(device)\\n    next_state = torch.FloatTensor(next_state).to(device)\\n    action     = torch.FloatTensor(action).to(device)\\n    reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\\n    done       = torch.FloatTensor(np.float32(done)).unsqueeze(1).to(device)\\n\\n    predicted_q_value1 = soft_q_net1(state, action)\\n    predicted_q_value2 = soft_q_net2(state, action)\\n    predicted_value    = value_net(state)\\n    new_action, log_prob, epsilon, mean, log_std = policy_net.evaluate(state)\\n\\n# Training Q Function\\n    target_value = target_value_net(next_state)\\n    target_q_value = reward + (1 - done) * gamma * target_value\\n    q_value_loss1 = soft_q_criterion1(predicted_q_value1, target_q_value.detach())\\n    q_value_loss2 = soft_q_criterion2(predicted_q_value2, target_q_value.detach())\\n    print(\"Q Loss\")\\n    print(q_value_loss1)\\n    soft_q_optimizer1.zero_grad()\\n    q_value_loss1.backward()\\n    soft_q_optimizer1.step()\\n    soft_q_optimizer2.zero_grad()\\n    q_value_loss2.backward()\\n    soft_q_optimizer2.step()    \\n# Training Value Function\\n    predicted_new_q_value = torch.min(soft_q_net1(state, new_action),soft_q_net2(state, new_action))\\n    target_value_func = predicted_new_q_value - log_prob\\n    value_loss = value_criterion(predicted_value, target_value_func.detach())\\n    print(\"V Loss\")\\n    print(value_loss)\\n    value_optimizer.zero_grad()\\n    value_loss.backward()\\n    value_optimizer.step()\\n# Training Policy Function\\n    policy_loss = (log_prob - predicted_new_q_value).mean()\\n\\n    policy_optimizer.zero_grad()\\n    policy_loss.backward()\\n    policy_optimizer.step()\\n    \\n    \\n    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\\n        target_param.data.copy_(\\n            target_param.data * (1.0 - soft_tau) + param.data * soft_tau\\n        )\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def update(batch_size,gamma=0.99,soft_tau=1e-2,):\n",
    "    \n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    state      = torch.FloatTensor(state).to(device)\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    action     = torch.FloatTensor(action).to(device)\n",
    "    reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\n",
    "    done       = torch.FloatTensor(np.float32(done)).unsqueeze(1).to(device)\n",
    "\n",
    "    predicted_q_value1 = soft_q_net1(state, action)\n",
    "    predicted_q_value2 = soft_q_net2(state, action)\n",
    "    predicted_value    = value_net(state)\n",
    "    new_action, log_prob, epsilon, mean, log_std = policy_net.evaluate(state)\n",
    "\n",
    "# Training Q Function\n",
    "    target_value = target_value_net(next_state)\n",
    "    target_q_value = reward + (1 - done) * gamma * target_value\n",
    "    q_value_loss1 = soft_q_criterion1(predicted_q_value1, target_q_value.detach())\n",
    "    q_value_loss2 = soft_q_criterion2(predicted_q_value2, target_q_value.detach())\n",
    "    print(\"Q Loss\")\n",
    "    print(q_value_loss1)\n",
    "    soft_q_optimizer1.zero_grad()\n",
    "    q_value_loss1.backward()\n",
    "    soft_q_optimizer1.step()\n",
    "    soft_q_optimizer2.zero_grad()\n",
    "    q_value_loss2.backward()\n",
    "    soft_q_optimizer2.step()    \n",
    "# Training Value Function\n",
    "    predicted_new_q_value = torch.min(soft_q_net1(state, new_action),soft_q_net2(state, new_action))\n",
    "    target_value_func = predicted_new_q_value - log_prob\n",
    "    value_loss = value_criterion(predicted_value, target_value_func.detach())\n",
    "    print(\"V Loss\")\n",
    "    print(value_loss)\n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "# Training Policy Function\n",
    "    policy_loss = (log_prob - predicted_new_q_value).mean()\n",
    "\n",
    "    policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "    \n",
    "    \n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "        )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_agent = SAC(lr=LR,gamma=GAMMA,batch_size=BATCH_SIZE,tau=TAU,\n",
    "                eps_start=EPS_START,eps_end=EPS_END,eps_dec=EPS_DECAY,\n",
    "                n_observations=n_observations,n_actions=n_actions)\n",
    "\n",
    "sac_agent_0 = SAC(lr=LR,gamma=GAMMA,batch_size=BATCH_SIZE,tau=TAU,\n",
    "                eps_start=EPS_START,eps_end=EPS_END,eps_dec=EPS_DECAY,\n",
    "                n_observations=n_observations,n_actions=n_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m agent_score\u001b[39m.\u001b[39mappend(total_reward_player_1)\n\u001b[0;32m     40\u001b[0m \u001b[39mprint\u001b[39m(truncation)\n\u001b[1;32m---> 42\u001b[0m sac_agent_0\u001b[39m.\u001b[39;49mupdate(previous_state,state,reward,termination)\n\u001b[0;32m     43\u001b[0m sac_agent\u001b[39m.\u001b[39mupdate(previous_state,state,reward,termination)\n\u001b[0;32m     44\u001b[0m \u001b[39m#sac_agent.clear_memory()\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m#sac_agent.learn(previous_state,last_action_player_1,total_reward_player_1,state)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 99\u001b[0m, in \u001b[0;36mSAC.update\u001b[1;34m(self, state, new_state, reward, done)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic_optimizer_2\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     98\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_optimizer_1\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> 99\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_optimizer_2\u001b[39m.\u001b[39;49mstep()\n",
      "File \u001b[1;32mc:\\Users\\koki6\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\koki6\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\koki6\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     adam(\n\u001b[0;32m    142\u001b[0m         params_with_grad,\n\u001b[0;32m    143\u001b[0m         grads,\n\u001b[0;32m    144\u001b[0m         exp_avgs,\n\u001b[0;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    147\u001b[0m         state_steps,\n\u001b[0;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\koki6\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m func(params,\n\u001b[0;32m    282\u001b[0m      grads,\n\u001b[0;32m    283\u001b[0m      exp_avgs,\n\u001b[0;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    286\u001b[0m      state_steps,\n\u001b[0;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[0;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[0;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[1;32mc:\\Users\\koki6\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adam.py:389\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    387\u001b[0m     torch\u001b[39m.\u001b[39mmaximum(max_exp_avg_sqs[i], exp_avg_sq, out\u001b[39m=\u001b[39mmax_exp_avg_sqs[i])\n\u001b[0;32m    388\u001b[0m     \u001b[39m# Use the max. for normalizing running avg. of gradient\u001b[39;00m\n\u001b[1;32m--> 389\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39;49madd_(eps)\n\u001b[0;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Inicializa pygame\n",
    "#pygame.init()\n",
    "\n",
    "# Crea la ventana\n",
    "#screen = pygame.display.set_mode ( (400,400),pygame.RESIZABLE )\n",
    "#pygame.VIDEORESIZE\n",
    "\n",
    "agent_score = []\n",
    "\n",
    "num_episodes = 1500\n",
    "total_reward_player_0 = 0\n",
    "total_reward_player_1 = 0\n",
    "last_action_player_1 = 0\n",
    "previous_state = observation\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "\n",
    "\n",
    "    state = env.reset()\n",
    "    #env.render()\n",
    "    \n",
    "\n",
    "\n",
    "    for agent in env.agent_iter():\n",
    "        #print(agent)\n",
    "        state, reward, termination, truncation, info = env.last()\n",
    "        #sac_agent.update_memory(state, reward, termination, truncation, info)\n",
    "\n",
    "\n",
    "        if termination or truncation:\n",
    "                #print(env.rewards)\n",
    "                total_reward_player_0 = total_reward_player_0 + env.rewards[\"player_0\"]\n",
    "                total_reward_player_1 = total_reward_player_1 + env.rewards[\"player_1\"]\n",
    "\n",
    "                sac_agent_0.optimize()\n",
    "                sac_agent.optimize()\n",
    "                \n",
    "                agent_score.append(total_reward_player_1)\n",
    "\n",
    "                sac_agent_0.update(previous_state,state,reward,termination)\n",
    "                sac_agent.update(previous_state,state,reward,termination)\n",
    "                #sac_agent.clear_memory()\n",
    "                #sac_agent.learn(previous_state,last_action_player_1,total_reward_player_1,state)\n",
    "\n",
    "                break\n",
    "        \n",
    "        if(agent == \"player_0\"):\n",
    "            #print(\"Player 1\")\n",
    "            #mask = state[\"action_mask\"]\n",
    "            #action = env.action_space(agent).sample(mask)  # this is where you would insert your policy\n",
    "            action = sac_agent_0.choose_action(agent,state)\n",
    "            #print(action)\n",
    "            env.step(action)\n",
    "        else:\n",
    "            #print(\"Player 2\")\n",
    "            \n",
    "            #mask = state[\"action_mask\"]\n",
    "            #action = env.action_space(agent).sample(mask)  # this is where you would insert your policy\n",
    "            action= sac_agent.choose_action(agent,state)\n",
    "\n",
    "            #state_tensor = torch.FloatTensor(np.array(state[\"observation\"]).reshape(1,-1))\n",
    "\n",
    "            #action = policy_net.act(state_tensor)\n",
    "            #print(action)\n",
    "            #print(action)\n",
    "            #action = int(input(\"Elige la columna: \\n\")) - 1 \n",
    "            env.step(action) \n",
    "\n",
    "            #new_state, new_reward, new_termination, new_truncation, new_info = env.last()\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            #last_action_player_1 = action \n",
    "        previous_state = state\n",
    "    env.close()\n",
    "\n",
    "print(\"Total score player 1: \" + str(total_reward_player_0))\n",
    "print(\"Total score player 2: \" + str(total_reward_player_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(agent_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nReferencias:\\n\\nhttps://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\\n\\n'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Referencias:\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
